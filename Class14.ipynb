{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAAgFEO6VcglB6hOd6CrGW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","file_path = \"/mnt/data/employees.csv\"\n","df = pd.read_csv(file_path)\n","# Display first few rows\n","print(df.head())\n","\n","# 2\n","average_salary_by_department = df.groupby(\"DEPARTMENT_ID\")[\"SALARY\"].mean()\n","print(average_salary_by_department)\n","\n","# 3\n","highest_paid_department = average_salary_by_department.idxmax()\n","highest_avg_salary = average_salary_by_department.max()\n","print(f\"Department {highest_paid_department} has the highest average salary: ${highest_avg_salary:.2f}\")"],"metadata":{"id":"3KU_w7-b_wha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    def _best_split(self, X, y):\n","        \"\"\"Find the best split for a node using gain ratio\"\"\"\n","        best_gain_ratio = -1\n","        best_feature = None\n","        best_threshold = None\n","        best_splits = None\n","\n","        current_entropy = self._entropy(y)\n","        n_samples = len(y)\n","\n","        for feature_idx in range(self.n_features):\n","            # Handle numerical features\n","            if isinstance(X[0, feature_idx], (int, float)):\n","                thresholds = np.unique(X[:, feature_idx])\n","                for threshold in thresholds:\n","                    left_idxs = X[:, feature_idx] <= threshold\n","                    right_idxs = X[:, feature_idx] > threshold\n","\n","                    if sum(left_idxs) == 0 or sum(right_idxs) == 0:\n","                        continue\n","\n","                    # Calculate information gain\n","                    n_left, n_right = sum(left_idxs), sum(right_idxs)\n","                    e_left, e_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n","                    info_gain = current_entropy - (n_left/n_samples * e_left + n_right/n_samples * e_right)\n","\n","                    # Calculate split info (for gain ratio)\n","                    split_info = -((n_left/n_samples) * log2(n_left/n_samples) +\n","                                  (n_right/n_samples) * log2(n_right/n_samples))\n","\n","                    if split_info == 0:  # Avoid division by zero\n","                        continue\n","\n","                    gain_ratio = info_gain / split_info\n","\n","                    if gain_ratio > best_gain_ratio:\n","                        best_gain_ratio = gain_ratio\n","                        best_feature = feature_idx\n","                        best_threshold = threshold\n","                        best_splits = None\n","\n","            # Handle categorical features\n","            else:\n","                unique_values = np.unique(X[:, feature_idx])\n","                splits = {}\n","                for value in unique_values:\n","                    splits[value] = X[:, feature_idx] == value\n","\n","                # Calculate information gain\n","                child_entropy = 0\n","                split_info = 0\n","                for value, idxs in splits.items():\n","                    if sum(idxs) == 0:\n","                        continue\n","                    proportion = sum(idxs) / n_samples\n","                    child_entropy += proportion * self._entropy(y[idxs])\n","                    split_info -= proportion * log2(proportion)\n","\n","                info_gain = current_entropy - child_entropy\n","\n","                if split_info == 0:  # Avoid division by zero\n","                    continue\n","\n","                gain_ratio = info_gain / split_info\n","\n","                if gain_ratio > best_gain_ratio:\n","                    best_gain_ratio = gain_ratio\n","                    best_feature = feature_idx\n","                    best_threshold = None\n","                    best_splits = splits\n","\n","        return best_feature, best_threshold, best_splits"],"metadata":{"id":"7wd1WvOsDKnc"},"execution_count":null,"outputs":[]}]}